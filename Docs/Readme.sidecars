Sidecars are sets of mpi processes doing work separately
from the main calculation.  There can be multiple sidecars,
and they and the calculation can be resized during the run.
The number of sidecars can also change during the run.
Typically main will coordinate resizing and communicating
with the sidecars as appropriate.

Sidecars are implemented with mpi communicators which are
separate from the AMReX global communicator.  Extra
communicators are created in AMReX when the sicecars
are resized to facilitate communication between the
calculation and the sidecars (inter communicators).
The AMReX global communicator is still available and
the user can create their own communicators at any time.

List of AMReX functions.
  Functions to create and resize sidecars.

  // ---- This version makes one sidecar (number zero)
  // ---- with sidecar ranks at the high end of the
  // ---- global rank set.
  void SetNProcsSidecars (int nscp);

  // ---- This version sets sidecar ranks according to the
  // ---- Vector<int> inputs
  // ---- compRanksInAll[0] must == 0  this restriction may
  // ---- be removed in the future
  // ---- the intersection of all ranks in all arrays must
  // ---- be null and the union must include all ranks in
  // ---- the AMReX global communicator
  void SetNProcsSidecars (const Vector<int> &compRanksInAll,
                          const Vector<Vector<int> > &sidecarRanksInAll);
						   
  Functions to communicate data.

Example code.
  Example code is in:  AMReX/Tutorials/Sidecar_EX1


Resizing the calculation:

  Larger sidecar(s)/smaller calculation.
    amrptr->AddProcsToSidecar(nSidecarProcs, prevSidecarProcs);
    SetNProcsSidecars(...);

  Smaller sidecar(s)/larger calculation.
    SetNProcsSidecars(...);
    amrptr->AddProcsToComp(nSidecarProcs, prevSidecarProcs);

  Mixing ranks.
    The ranks in SetNProcsSidecars can be mixed and do not need
    to be in order, but resizing with mixed ranks is not currently
    supported because resizing the calculation may involve moving
    processes both to and from the calculation at the same time.
    If there is a need for this it can be supported, I just need
    a good test case to make it work.


    // Broadcasts to intercommunicators have weird syntax. See below.
    // Whichever proc is actually broadcasting the data uses MPI_ROOT; all
    // other procs in that same communicator use MPI_PROC_NULL. On the
    // receiving end, the source rank is the rank of the broadcasting process
    // within its local communicator, *not* its rank in MPI_COMM_WORLD.
    // (Usually broadcasts will come from IOProcessor(), which is typically
    // rank 0.)
    const int MPI_IntraGroup_Broadcast_Rank = ParallelDescriptor::IOProcessor() ? MPI_ROOT : MPI_PROC_NULL;

